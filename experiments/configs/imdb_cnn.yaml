project:
  seed: 1337
  device: "cpu"        # "cuda", "cpu", or "auto"

data:
  root: "data/raw/aclImdb"
  use_official_test: true
  val_ratio: 0.2
  lowercase: true
  remove_html_breaks: true
  normalize_unicode: true
  max_len: 400      # was 256
  min_freq: 1       # was 3
  max_vocab: 20000
  pad_token: "<pad>"
  unk_token: "<unk>"
  num_workers: 4
  batch_size: 64

model:
  name: "cnn_text"
  embedding_dim: 200      # was 100
  filter_sizes: [3, 4, 5]
  num_filters: 150        # was 100
  dropout: 0.5
  num_classes: 2

train:
  epochs: 20
  optimizer: "adam"
  lr: 0.001
  weight_decay: 0.0
  early_stop_patience: 5
  grad_clip: 5.0
  mixed_precision: false

log:
  dir: "experiments/logs"
  csv_name: "imdb_cnn_clean.csv"
  ckpt_path: "experiments/logs/imdb_cnn.pt"

attacks:
  # evaluate on this many test examples (None = full test set)
  max_eval_examples: 500    # you can raise/lower this later # was 500

  keyword:
    max_changes_list: [1, 2, 3]   # budgets k for word substitutions # was 1, 2 ,3
    max_fraction_changed: 0.2     # ≤20% of real tokens can be changed # was 0.2
    top_k_words: 8                # only attack top-8 important words # was 8
    max_synonyms: 20              # nearest neighbours to consider per word # was 20

  char:
    max_edits_list: [1, 2, 3]     # budgets m for character edits # was 1, 2, 3
    max_char_frac: 0.15           # ≤15% of characters may be modified # was 0.15